# 监督学习

# 梯度下降：

## 简单原理（以一元为例）：

1. 确定预测函数（线性回归为例） ---直线....

   一元线性回归：寻找斜率参数w 确定预测函数y=wx

   <img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517154935493.png" alt="预测函数" style="zoom:33%;" /> 

   

2. 确定代价函数

   量化数据偏离程度（误差）--常见：（均方误差）确定参数

   ----最小二乘法 ---得到二次函数

   若代价函数为**y=wx+b** （两个参数）------>**抛物面**  最低点

   **最小二乘法**也可以**拟合高阶曲线**

   最小二乘法就是概率密度是高斯分布时最大自然估计的特殊情况

   

   <img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517160005605.png" alt="代价函数" style="zoom:25%;" /> 

3. 明确搜索方向--**梯度**计算（代价函数导数--斜率）

   <img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517154609086.png" alt="学习率" style="zoom:33%;" /> 

4. **学习率**（决定步长）

   学习率*斜率=步长 （越接近驻点越慢-----最终收敛在最低点）

5. 循环3.4直到找到最低点 ---确定参数w

## 算法：

​	1.bgd：批量梯度下降法（稳）

<img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517155053821.png" alt="image-20220517155053821" style="zoom:25%;" /> 

​	2.sgd随机梯度下降法（快，缺乏精准度）		

<img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517155119867.png" alt="image-20220517155119867" style="zoom:25%;" />                      

3. mbgd 小批量梯度下降法(又快又稳)

   <img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517155252259.png" alt="image-20220517155252259" style="zoom:25%;" />     

4. 瞎子下山：最速下降法

## 优缺点：

1. 对学习率敏感：

    学习率太大：反复横跳  

   太小：效率低，浪费计算量

2. 处理bgd外 无法保证找到全局最优解



## 更优的下降算法：

1. AdaGrad  --动态学习率 
2. RMSProp--优化动态学习率
3. AdaDelta --无需设置学习率
4. Adam  --融合AdaGrad 和RMSProp
5. Momentun ---模拟动量（惯性）
6. FTRL  
7. ...



# 神经网络基本模型

（对数据有效决策分类）

<img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517162112252.png" alt="image-20220517162112252" style="zoom:25%;" /> 

## 单层神经网络：输入 输出

### 神经元模型（感知机）

<img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517163419993.png" alt="image-20220517163419993" style="zoom:25%;" /> 

#### 激活函数（线性叠加---->加入非线性）：

 <img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517163447769.png" alt="image-20220517163447769" style="zoom: 33%;" />

#### 效果：

　我们可以用**决策分界**来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是3维的时候，就是划出一个平面，当数据的维度是n维时，就是划出一个n-1维的超平面。

 

## 两层：

###	特点

两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，**中间层和输出层都是计算层**

（可能存在**偏置结点**：无输入，仅储存）

### 功能：

#### 		1.线性分类（空间变换）

　与单层神经网络不同。**理论证明，两层神经网络可以无限逼近任意连续函数。**

也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。

#### 	原因：

隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。

两层神经网络可以做非线性分类的关键--隐藏层。联想到我们一开始推导出的矩阵公式，我们知道，矩阵和向量相乘，本质上就是对向量的坐标空间进行一个变换。因此，**隐藏层的参数矩阵的作用就是使得数据的原始坐标空间从线性不可分，转换成了线性可分。**

　　两层神经网络通过两层的线性模型模拟了数据内真实的非线性函数。因此，多层的神经网络的本质就是复杂函数拟合。

#### 2.BP算法（反向传播）实现训练、预测

一般利用**sigmoid**函数作激活函数（达到阈值响应）

最小化损失函数（**代价函数**）-------通过**梯度下降**和**神经网络反向传播**确定权重



<!--ps:　反向传播算法的启示是数学中的链式法则。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从BP算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做**泛化** （generalization），相关方法被称作正则化（regularization）。神经网络中常用的泛化技术有权重衰减等          90年代中期，由Vapnik等人发明的SVM（Support Vector Machines，支持向量机）算法诞生，很快就在若干个方面体现出了对比神经网络的优势：无需调参；高效；全局最优解。基于以上种种理由，SVM迅速打败了神经网络算法成为主流。-->

## 多层：（深度学习）

### 特点：

更高维度，更深入的**表示特征**，以及更强的函数模拟能力。

更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的**抽象表示更深入。**例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。

<img src="C:\Users\86172\AppData\Roaming\Typora\typora-user-images\image-20220517171012917.png" alt="image-20220517171012917" style="zoom:25%;" /> 

#### 训练与预测：

**激活函数**：*ReLU函数*

ReLU函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是ReLU函数。ReLU函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是y=max(x,0)。简而言之，在x大于0，输出就是输入，而在x小于0时，输出就保持为0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。

<!--在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现**过拟合现象**。因此正则化技术就显得十分重要。目前，Dropout技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。-->

### 功能：

更好的区分与分类能力,以及更强的函数模拟能力。　更强的函数模拟能力是由于随着层数的增加，整个网络的参数就越多。而神经网络其实本质就是模拟特征与目标之间的真实关系函数的方法，更多的参数意味着其模拟的函数可以更加的复杂，可以有更多的**容量**（capcity）去拟合真正的关系。

## 总结：

1.对于高维数据 ：分类线----->分类面

2.概念 泛化（到测试集）  过拟合：模型过于复杂不能很好泛化到测试集  欠拟合：过于简单的模型

3.图示

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE1LmNuYmxvZ3MuY29tL2Jsb2cvNjczNzkzLzIwMTUxMi82NzM3OTMtMjAxNTEyMjgxMzQwMTYxMjAtMTA5MTM1MTA5Ni5qcGc?x-oss-process=image/format,png" alt="img" style="zoom:25%;" /> 



<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE1LmNuYmxvZ3MuY29tL2Jsb2cvNjczNzkzLzIwMTUxMi82NzM3OTMtMjAxNTEyMjgxNzAxNDkxMzUtMjEwNzA4NzQ2Mi5qcGc?x-oss-process=image/format,png" alt="img" style="zoom: 33%;" >  

 4.通过神经元升维，提高线性转换能力 ，通过多个隐藏层，增加非线性转换次数。

5. 其他模型：卷积神经网络（CNN）  循环神经网络...

    

